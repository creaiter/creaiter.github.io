
<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Styles -->
    <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1.0">

    <!-- Favicon -->
    <link rel="shortcut icon" href="favicon.ico">
    
    <title>Creaiter</title>

    <script src="https://kit.fontawesome.com/35ecbf2ff1.js" crossorigin="anonymous"></script>
    
    <script type="text/javascript" src="assets/javascript/growDiv.js"></script>  
</head>
<body>
    <div class="container">
  <div class="header">
    <h1 class="title"><span style="text-transform: capitalize;">Jinbae Park</span></h1>
    
      <input type="checkbox" id="switch" name="mode" class="toggle-dark"></input>
      <label for="switch"><i id="moon" data-feather="moon" fill="var(--fg-color)"></i></label>
    
  </div>
  <div class="container-block">
    <div class="sidebar">
      

<section class="contact">
    <div class="title">Contact</div>

    <div class="contact-item" style='letter-spacing:10px'>
        <a href="mailto:qkrwlsqo94@gmail.com" style="color: var(--fg-color);"><i class="fas fa-envelope fa-lg"></i></a>
        <a href="https://github.com/creaiter" style="color: var(--fg-color);"><i class="fab fa-github fa-lg"></i></a>
        <a href="https://scholar.google.com/citations?user=e4UxwckAAAAJ" style="color: var(--fg-color);"><i class="fas fa-graduation-cap fa-lg"></i></a>
        <a href="https://linkedin.com/in/jinbae-park" style="color: var(--fg-color);"><i class="fab fa-linkedin fa-lg"></i></a>
    </div>

    

    

    

    

    

    
</section>

      

<section class="interests">
    <div class="title">Interests</div>
    
        <div class="interests-item">
            <div class="domain">Network Compression</div>
        </div>
    
        <div class="interests-item">
            <div class="domain">Efficient Learning</div>
        </div>
    
        <div class="interests-item">
            <div class="domain">Deployment on Edge</div>
        </div>
    
</section>

      

<section class="education">
    <div class="title">Education</div>
    
        <div class="education-item">
            <div class="degree">MS in Computer Science</div>
            <div class="university">Kyung Hee University</div> 
            <div class="time">Mar 2020 - Feb 2022</div>
        </div>
    
        <div class="education-item">
            <div class="degree">BS in Computer Science</div>
            <div class="university">Kyung Hee University</div> 
            <div class="time">Mar 2013 - Feb 2020</div>
        </div>
    
</section>

      

<section class="languages">
    <div class="title">Languages</div>
    
        <div class="idiom">Korean</div>
    
        <div class="idiom">English (OPIc IH)</div>
    
</section>

      <!-- 
 -->
      <!-- 
 -->
    </div>

    <div class="main">
      

<section class="career-profile">
    <h2 class="title">Career Profile</h2>
    <div class="details">My research domain is highly related to obtaining efficient neural networks by applying compression techniques, such as
quantization, pruning, and distillation, for deployment of the networks on edge devices.
</div>
</section>

      

<section class="common">
    <h2 class="title">Publications</h2>
    
        <div class="items">
            <div class="item-title">Centralized Quantization: Preserving a Few Large Weights to Relieve theDegradation in Accuracy by Ternary Weights</div>
            <div class="item-content">Jinbae Park, Sung-Ho Bae</div>
            <div class="item-inst">[Submitted]
                
            </div>
            <div class="detail" id="pub-grow1">
                <div class='measuringWrapper'>
                    
                    
                </div>
            </div>
        </div>
    
        <div class="items">
            <div class="item-title">Distilling Global and Local Logits with Densely Connected Relations</div>
            <div class="item-content">Youmin Kim, Jinbae Park, YounHo Jang, Muhammad Ali, Tae-Hyun Oh, Sung-Ho Bae</div>
            <div class="item-inst">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021
                
                    <span class="bttn-loc">
                        <input class="bttn" type="button" onclick="growDiv('pub-grow2', 'pub-button2')" value="details" id="pub-button2">
                    </span>
                
            </div>
            <div class="detail" id="pub-grow2">
                <div class='measuringWrapper'>
                    
                        
                            <div class="detail-content">
                                <span class="detail-key">Keywords: </span>Logit Distillation, Local Information
                            </div>
                        
                            <div class="detail-content">
                                <span class="detail-key">Summary: </span>In prevalent knowledge distillation for image classificiation,
global logits computed by global average pooling are generally utilized to transfer this knowledge from teacher to student.
In this work, to overcome the limited information in spatial context,
we also transfer local knowledge, exploiting local logits computed by spatial average pooling.
The richness of local information shows favorable accuracy improvement against the state-of-the-art methods.

                            </div>
                        
                    
                    
                        <div class="detail-content">
                            <span class="detail-key">Materials: </span>
                            
                                [<a class="content-link" href=""></a>TBC<a></a>]
                            
                        </div>
                    
                </div>
            </div>
        </div>
    
        <div class="items">
            <div class="item-title">Search for Optimal Data Augmentation Policy for Environmental Sound Classification with Deep Neural Networks</div>
            <div class="item-content">Jinbae Park, Teerath Kumar, Sung-Ho Bae</div>
            <div class="item-inst">Journal of Broadcast Engineering (JBE), 25.6, 2020
                
                    <span class="bttn-loc">
                        <input class="bttn" type="button" onclick="growDiv('pub-grow3', 'pub-button3')" value="details" id="pub-button3">
                    </span>
                
            </div>
            <div class="detail" id="pub-grow3">
                <div class='measuringWrapper'>
                    
                        
                            <div class="detail-content">
                                <span class="detail-key">Keywords: </span>Sound Classification, Data Augmentation, Augmentation Search
                            </div>
                        
                            <div class="detail-content">
                                <span class="detail-key">Summary: </span>This paper aims to explore the search for optimal augmentation policy in the environmental sound classification task.
By selectively combining the augmentation methods, such as adding noise, pitch shift, time stretch, etc, we could outperform the
state-of-the-art methods on the ESC-50 dataset.

                            </div>
                        
                    
                    
                        <div class="detail-content">
                            <span class="detail-key">Materials: </span>
                            
                                [<a class="content-link" href="https://www.koreascience.or.kr/article/JAKO202001955917251.page">article</a>]
                            
                                [<a class="content-link" href="https://www.koreascience.or.kr/article/JAKO202001955917251.pdf">pdf</a>]
                            
                        </div>
                    
                </div>
            </div>
        </div>
    
</section>

      

<section class="common">
    <h2 class="title">Projects</h2>
    
        <div class="items">
            <div class="item-title">A Study on Compression of Deep Neural Networks by Quantization and Pruning</div>
            <div class="item-inst">IITP, Republic of Korea
                <span class="time">Jan 2021 - Dec 2021</span>
            </div>
            <div class="item-content">Deployment of compressed models on edge devices.
                
                    <span class="bttn-loc">
                        <input class="bttn" type="button" onclick="growDiv('p-grow1', 'p-button1')" value="details" id="p-button1">
                    </span>
                
            </div>
            <div class="detail" id="p-grow1">
                <div class='measuringWrapper'>
                    
                        
                            <div class="detail-content">
                                <span class="detail-key">Description: </span>Development of the efficient quantization and pruning methods by dynamic training and 
the combination of them to obtain the high compression ratio.
Deployment of the lightened models on several edge devices constrained in harwarde resource,
such as Google Pixel 3, Raspberry Pi 4, and Nvidia Jetson Xavier NX.

                            </div>
                        
                            <div class="detail-content">
                                <span class="detail-key">Technologies: </span>PyTorch Mobile, NVIDIA TensorRT, ONNX
                            </div>
                        
                    
                    
                        <div class="detail-content">
                            <span class="detail-key">Materials: </span>
                            
                                [<a class="content-link" href="https://github.com/mlvc-lab/Edge_Deployment">github</a>]
                            
                        </div>
                    
                </div>
            </div>
        </div>
    
        <div class="items">
            <div class="item-title">A Challenge for Deep Model Compression based on Joint Learning with Vision Applications</div>
            <div class="item-inst">IITP, Republic of Korea
                <span class="time">Aug 2020 - Dec 2020</span>
            </div>
            <div class="item-content">4th place prize in the challenge.
                
                    <span class="bttn-loc">
                        <input class="bttn" type="button" onclick="growDiv('p-grow2', 'p-button2')" value="details" id="p-button2">
                    </span>
                
            </div>
            <div class="detail" id="p-grow2">
                <div class='measuringWrapper'>
                    
                        
                            <div class="detail-content">
                                <span class="detail-key">Description: </span>Compressing the models classifying images and detecting objects by tyring various methods,
e.g., data augmentation, quantization, lightweight architecture, etc.

                            </div>
                        
                            <div class="detail-content">
                                <span class="detail-key">Roles: </span>i) Taking responsibility for quantization implementation to reduce model size;
ii) Combinating the techniques, such as quantization, pruning, and distillation with managing the overall codes;
iii) Applying NVIDIA DALI and TensorRT to accelerate the inference procedure; and
iV) Optimizing minor factors, such as image size, confidence threshold, removing letter-box, etc.

                            </div>
                        
                    
                    
                        <div class="detail-content">
                            <span class="detail-key">Materials: </span>
                            
                                [<a class="content-link" href="https://github.com/mlvc-lab/AIChallenge_4th_Round1">github</a>]
                            
                        </div>
                    
                </div>
            </div>
        </div>
    
        <div class="items">
            <div class="item-title">A Challenge for Accurate Voice Source Localization on Drones based on Deep Neural Networks</div>
            <div class="item-inst">IITP, Republic of Korea
                <span class="time">Sept 2019 - Dec 2020</span>
            </div>
            <div class="item-content">1st place prize in the challenge.
                
                    <span class="bttn-loc">
                        <input class="bttn" type="button" onclick="growDiv('p-grow3', 'p-button3')" value="details" id="p-button3">
                    </span>
                
            </div>
            <div class="detail" id="p-grow3">
                <div class='measuringWrapper'>
                    
                        
                            <div class="detail-content">
                                <span class="detail-key">Description: </span>The goal of this project is to localize the activity and of human voice calling for rescue
and the direction of arrival of the human, even though there is very loud noise from the drones in flight.

                            </div>
                        
                            <div class="detail-content">
                                <span class="detail-key">Roles: </span>i) Augmenting a single channel voice by convoling to generate a double channel one having an angle
and by adding environmental sound and drone sound as noise;
ii) Designing a data preprocess step to concentrate on the quiet section in the noisy audio;
iii) Analyzing how the models distinguish the angle of voice using GCC gram features,
varing the intensity of noise; and
iv) Training models with different conditions to improve the performance.

                            </div>
                        
                    
                    
                        <div class="detail-content">
                            <span class="detail-key">Materials: </span>
                            
                                [<a class="content-link" href="https://github.com/IRIS-AUDIO/challenge">github</a>]
                            
                        </div>
                    
                </div>
            </div>
        </div>
    
</section>

      

<section class="common">
    <h2 class="title">Experience</h2>
    
        <div class="items">
            <div class="item-title">Compressing a Cascaded Regression Model for Facial Landmark Detection</div>
            <div class="item-inst">Hyprsense Inc., USA
                <span class="time">Sept 2018 - Jan 2019</span>
            </div>
            <div class="item-content">Research internship
                
                    <span class="bttn-loc">
                        <input class="bttn" type="button" onclick="growDiv('exp-grow1', 'exp-button1')" value="details" id="exp-button1">
                    </span>
                
            </div>
            <div class="detail" id="exp-grow1">
                <div class='measuringWrapper'>
                    
                        
                            <div class="detail-content">
                                <span class="detail-key">Description: </span>The goal of this project is building a sparse cascaded regression model through sparse approximation
in truncated SVD.
Methodically, we exploited various regularization methods (ElasticNet, group Lasso and exponential
Lasso, etc) to select features and make sparse matrices. Furthermore, re-training was conducted
after matrix factorization to compensate a loss by the factorization. 

                            </div>
                        
                    
                    
                        <div class="detail-content">
                            <span class="detail-key">Materials: </span>
                            
                                [<a class="content-link" href="https://medium.com/@hyprsense/compressing-a-cascaded-regression-model-how-to-sparsify-the-matrix-4c4013cee47c">blog</a>]
                            
                        </div>
                    
                </div>
            </div>
        </div>
    
        <div class="items">
            <div class="item-title">Developing of C Program for Accelerating Convolutional Neural Networks on FPGA boards</div>
            <div class="item-inst">Prof. Nikil Dutt, University of California Irvine, USA
                <span class="time">Jun 2018 - Oct 2018</span>
            </div>
            <div class="item-content">Research assistant
                
                    <span class="bttn-loc">
                        <input class="bttn" type="button" onclick="growDiv('exp-grow2', 'exp-button2')" value="details" id="exp-button2">
                    </span>
                
            </div>
            <div class="detail" id="exp-grow2">
                <div class='measuringWrapper'>
                    
                        
                            <div class="detail-content">
                                <span class="detail-key">Description: </span>This project aims to deploy various CNN architectures on FPGA boards.
The original architectures written in Keras can be optimized and translated to verilog by Vivado HLS.
In this project, I helped to make a program which can convert the python code for the Keras models
to C language for enterting them into the Vivado HLS.

                            </div>
                        
                    
                    
                </div>
            </div>
        </div>
    
        <div class="items">
            <div class="item-title">Swapping Facial Expressions of the People in Images</div>
            <div class="item-inst">Alchera Inc., Republic of Korea
                <span class="time">Jan 2018 - Feb 2018</span>
            </div>
            <div class="item-content">Research internship
                
                    <span class="bttn-loc">
                        <input class="bttn" type="button" onclick="growDiv('exp-grow3', 'exp-button3')" value="details" id="exp-button3">
                    </span>
                
            </div>
            <div class="detail" id="exp-grow3">
                <div class='measuringWrapper'>
                    
                        
                            <div class="detail-content">
                                <span class="detail-key">Description: </span>Changing facial expressions of different people using the extracted facial landmarks.
By dividing a face area with Delaunary trangulation, we can exchange each position-matched triangle
after linear tranfsormation. We also applied several algorithms to compensate the distortion by
the tranformation, especially for tooth and mouth expressions.

                            </div>
                        
                    
                    
                </div>
            </div>
        </div>
    
</section>

      

<section class="common">
    <h2 class="title">Others</h2>
    <div class="items">
        <div class="item-content">
            - Lab leader at <a class="content-link" href="https://sites.google.com/khu.ac.kr/mlvclab/team">MLVC</a>, Kyung Hee University
            <span class="time">Jan 2021 - Dec 2021</span>
        </div>
        <div class="item-content">
            - Teaching assistant at a deep learning course using CUDA programming
        </div>
    </div>
</section>

      <!-- 
 -->
    </div>
  </div>
</div>

</body>
<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>

  <script src="http://localhost:4000/assets/javascript/toggleDark.js"></script>

<script>
  feather.replace()
</script>
</html>