name: Jinbae Park
support_dark_mode: true
fork: false

# Sidebar
contact:
  email: #qkrwlsqo94@gmail.com
  github: #creaiter
  linkedin: #jinbae-park
  phone: 
  gitlab: 
  twitter: 

interests:
  - domain: Network Compression
  - domain: Efficient Learning
  - domain: Deployment on Edge

education:
  - degree: MS in Computer Science
    time: Mar 2020 - Feb 2022
    university: Kyung Hee University

  - degree: BS in Computer Science<br>and Electrical Engineering
    time: Mar 2013 - Feb 2020
    university: Kyung Hee University

languages:
  - idiom: Korean
  - idiom: English (OPIc IH)

skills:
  # - category: Backend
  #   skill: 
  #     - Go
  #     - Rust
  # - category: Frontend
  #   skill:
  #     - React
  #     - Typescript
  # - category: DevOps
  #   skill:
  #     - Docker
  #     - Kubernetes 


# Profile
profile: |
  My research domain is highly related to obtaining efficient neural networks by applying compression techniques, such as
  quantization, pruning, and distillation, for deployment of the networks on edge devices.


# Publications
publications:
  # - title: Selectively Regularized Pruning

  - title: "Centralized Quantization: Preserving a Few Large Weights to Relieve the Degradation in Accuracy by Ternary Weights"
    authors: Jinbae Park, Sung-Ho Bae
    conference: "[Submitted]"
    details:
    links: 

  - title: Distilling Global and Local Logits with Densely Connected Relations
    authors: Youmin Kim, Jinbae Park, YounHo Jang, Muhammad Ali, Tae-Hyun Oh, Sung-Ho Bae
    conference: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021
    details:
      - key: Keywords
        value: Logit Distillation, Local Information
      - key: Summary
        value: |
          In prevalent knowledge distillation for image classificiation,
          global logits computed by global average pooling are generally utilized to transfer this knowledge from teacher to student.
          In this work, to overcome the limited information in spatial context,
          we also transfer local knowledge, exploiting local logits computed by spatial average pooling.
          The richness of local information shows favorable accuracy improvement against the state-of-the-art methods.
    links: 
      - key: </a>TBC<a>
        value:

  - title: Search for Optimal Data Augmentation Policy for Environmental Sound Classification with Deep Neural Networks
    authors: Jinbae Park, Teerath Kumar, Sung-Ho Bae
    conference: Journal of Broadcast Engineering (JBE), 25.6, 2020
    details:
      - key: Keywords
        value: Sound Classification, Data Augmentation, Augmentation Search
      - key: Summary
        value: |
          This paper aims to explore the search for optimal augmentation policy in the environmental sound classification task.
          By selectively combining the augmentation methods, such as adding noise, pitch shift, time stretch, etc, we could outperform the
          state-of-the-art methods on the ESC-50 dataset.
    links: 
      - key: article
        value: "https://www.koreascience.or.kr/article/JAKO202001955917251.page"
      - key: pdf
        value: "https://www.koreascience.or.kr/article/JAKO202001955917251.pdf"

  
# Projects
projects:
  # - title: CAPEON

  - title: A Study on Compression of Deep Neural Networks by Quantization and Pruning
    time: Jan 2021 - Dec 2021
    institution: IITP, Republic of Korea
    onesentence: Deployment of compressed models on edge devices.
    details:
      - key: Description
        value: |
          Development of the efficient quantization and pruning methods by dynamic training and 
          the combination of them to obtain the high compression ratio.
          Deployment of the lightened models on several edge devices constrained in harwarde resource,
          such as Google Pixel 3, Raspberry Pi 4, and Nvidia Jetson Xavier NX.
      - key: Technologies
        value: PyTorch Mobile, NVIDIA TensorRT, ONNX # & runtime, TensorFlow Lite
    links:
      - key: github
        value: https://github.com/mlvc-lab/Edge_Deployment

  - title: A Challenge for Deep Model Compression based on Joint Learning with Vision Applications
    time: Aug 2020 - Dec 2020
    institution: IITP, Republic of Korea
    onesentence: 4th place prize in the challenge.
    details:
      - key: Description
        value: |
          Compressing the models classifying images and detecting objects by tyring various methods,
          e.g., data augmentation, quantization, lightweight architecture, etc.
      - key: Roles
        value: |
          i) Taking responsibility for quantization implementation to reduce model size;
          ii) Combinating the techniques, such as quantization, pruning, and distillation with managing the overall codes;
          iii) Applying NVIDIA DALI and TensorRT to accelerate the inference procedure; and
          iV) Optimizing minor factors, such as image size, confidence threshold, removing letter-box, etc.
    links:
      - key: github
        value: https://github.com/mlvc-lab/AIChallenge_4th_Round1

  - title: A Challenge for Accurate Voice Source Localization on Drones based on Deep Neural Networks
    time: Sept 2019 - Dec 2020
    institution: IITP, Republic of Korea
    onesentence: 1st place prize in the challenge.
    details:
      - key: Description
        value: |
          The goal of this project is to localize the activity and of human voice calling for rescue
          and the direction of arrival of the human, even though there is very loud noise from the drones in flight.
      - key: Roles
        value: |
          i) Augmenting a single channel voice by convoling to generate a double channel one having an angle
          and by adding environmental sound and drone sound as noise;
          ii) Designing a data preprocess step to concentrate on the quiet section in the noisy audio;
          iii) Analyzing how the models distinguish the angle of voice using GCC gram features,
          varing the intensity of noise; and
          iv) Training models with different conditions to improve the performance.
    links:
      - key: github
        value: https://github.com/IRIS-AUDIO/challenge


# Experience
experience:
  - title: Compressing a Cascaded Regression Model for Facial Landmark Detection
    time: Sept 2018 - Jan 2019
    institution: Hyprsense Inc., USA
    position: Research internship
    details:
      - key: Description
        value: |
          The goal of this project is building a sparse cascaded regression model through sparse approximation
          in truncated SVD.
          Methodically, we exploited various regularization methods (ElasticNet, group Lasso and exponential
          Lasso, etc) to select features and make sparse matrices. Furthermore, re-training was conducted
          after matrix factorization to compensate a loss by the factorization. 
    links:
      - key: blog
        value: https://medium.com/@hyprsense/compressing-a-cascaded-regression-model-how-to-sparsify-the-matrix-4c4013cee47c
  
  - title: Developing of C Program for Accelerating Convolutional Neural Networks on FPGA boards
    time: Jun 2018 - Oct 2018
    institution: Prof. Nikil Dutt, University of California Irvine, USA
    position: Research assistant
    details:
      - key: Description
        value: |
          This project aims to deploy various CNN architectures on FPGA boards.
          The original architectures written in Keras can be optimized and translated to verilog by Vivado HLS.
          In this project, I helped to make a program which can convert the python code for the Keras models
          to C language for enterting them into the Vivado HLS.
    links:

  - title: Swapping Facial Expressions of the People in Images
    time: Jan 2018 - Feb 2018
    institution: Alchera Inc., Republic of Korea
    position: Research internship
    details:
      - key: Description
        value: |
          Changing facial expressions of different people using the extracted facial landmarks.
          By dividing a face area with Delaunary trangulation, we can exchange each position-matched triangle
          after linear tranfsormation. We also applied several algorithms to compensate the distortion by
          the tranformation, especially for tooth and mouth expressions.
    links:

#   technologies_used: | 
#     Python, Tensorflow, Keras, Matlab


# Others
others: true
