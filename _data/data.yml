name: Jinbae Park
support_dark_mode: true
fork: false

# Sidebar
contact:
  email: #qkrwlsqo94@gmail.com
  github: #creaiter
  linkedin: #jinbae-park
  phone: 
  gitlab: 
  twitter: 

interests:
  - domain: Network Compression
  - domain: Efficient Learning
  - domain: Deployment on Edge

education:
  - degree: MS in Computer Science
    time: Mar 2020 - Feb 2022
    university: Kyung Hee University

  - degree: BS in Computer Science
    time: Mar 2013 - Feb 2020
    university: Kyung Hee University

languages:
  - idiom: Korean
  - idiom: English (OPIc IH)

skills:
  # - category: Backend
  #   skill: 
  #     - Go
  #     - Rust
  # - category: Frontend
  #   skill:
  #     - React
  #     - Typescript
  # - category: DevOps
  #   skill:
  #     - Docker
  #     - Kubernetes 


# Profile
profile: |
  My research domain is highly related to obtaining efficient neural networks by applying compression techniques, such as
  quantization, pruning, and distillation, for deployment of the networks on edge devices.


# Publications
publications:
  # - title: Selectively Regularized Pruning

  - title: "Centralized Quantization: Preserving a Few Large Weights to Relieve theDegradation in Accuracy by Ternary Weights"
    authors: Jinbae Park, Sung-Ho Bae
    conference: "[Submitted]"
    details:
    links: 

  - title: Distilling Global and Local Logits with Densely Connected Relations
    authors: Youmin Kim, Jinbae Park, YounHo Jang, Muhammad Ali, Tae-Hyun Oh, Sung-Ho Bae
    conference: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021
    details:
      - key: Keywords
        value: Logit Distillation, Local Information
      - key: Summary
        value: |
          In prevalent knowledge distillation for image classificiation,
          global logits computed by global average pooling are generally utilized to transfer this knowledge from teacher to student.
          In this work, to overcome the limited information in spatial context,
          we also transfer local knowledge, exploiting local logits computed by spatial average pooling.
          The richness of local information shows favorable accuracy improvement against the state-of-the-art methods.
    links: 
      - key: </a>TBC<a>
        value:

  - title: Search for Optimal Data Augmentation Policy for Environmental Sound Classification with Deep Neural Networks
    authors: Jinbae Park, Teerath Kumar, Sung-Ho Bae
    conference: Journal of Broadcast Engineering (JBE), 25.6, 2020
    details:
      - key: Keywords
        value: Sound Classification, Data Augmentation, Augmentation Search
      - key: Summary
        value: |
          This paper aims to explore the search for optimal augmentation policy in the environmental sound classification task.
          By selectively combining the augmentation methods, such as adding noise, pitch shift, time stretch, etc, we could outperform the
          state-of-the-art methods on the ESC-50 dataset.
    links: 
      - key: article
        value: "https://www.koreascience.or.kr/article/JAKO202001955917251.page"
      - key: pdf
        value: "https://www.koreascience.or.kr/article/JAKO202001955917251.pdf"

  
# Projects
projects:
  # - title: CAPEON
  - title: A Study on Compression of Deep Neural Networks by Quantization and Pruning
    time: Jan 2021 - Dec 2021
    institution: IITP, Republic of Korea
    onesentence: 
    details:
      - key: Description
        value: Deployment of lightened networks on edge devices, such as Google Pixel 3, Raspberry Pi 4, and Nvidia Jetson Xavier NX.
      - key: Role
        value: dfdf
      - key: Technologies used
        value: Python, Tensorflow, Keras, Matlab
    links:
      - key: github
        value: https://github.com/mlvc-lab/Edge_Deployment

  - title: Deep Model Compression based on Joint Learning for Vision Applications
    time: Aug 2020 - Dec 2020
    institution: IITP, Republic of Korea
    onesentence: 4th place prize in the challenge.
    details:
      - key: Description
        value: dfdf
      - key: Role
        value: dfdf
    links:
      - key: github
        value: https://github.com/mlvc-lab/AIChallenge_4th_Round1

  - title: Accurate Voice Source Localization on Drones based on Deep Neural Networks
    time: Sept 2019 - Dec 2020
    institution: IITP, Republic of Korea
    onesentence: 1st place prize in the challenge.
    details:
      - key: Description
        value: dfdf
      - key: Role
        value: dfdf
    links:
      - key: github
        value: https://github.com/IRIS-AUDIO/challenge


# Experience
experience:
  - title: Compression of the Regression Models for Face Landmark Detection
    time: Sept 2018 - Jan 2019
    institution: Research internship, Hyprsense Inc., USA
    onesentence: Building a compressed cascaded regression model with the sparsification of docomposed weight matrices by L1 based regularization methods.
    details:
      - key: Description
        value: dfdf
      - key: Role
        value: dfdf
    links:
      - key: blog
        value: https://medium.com/@hyprsense/compressing-a-cascaded-regression-model-how-to-sparsify-the-matrix-4c4013cee47c
  
  - title: Developing of C Program for Accelerating Convolutional Neural Networks on FPGA boards
    time: Jun 2018 - Oct 2018
    institution: Research assistant, Prof. Nikil Dutt, University of California Irvine, USA
    onesentence: Optimizing C programs of CNN models with Vivado HLS to deploy on FPGA boards.
    details:
      - key: Description
        value: dfdf
      - key: Role
        value: dfdf
    links:

  - title: Swapping Face and Facial Expressions of People
    time: Jan 2018 - Feb 2018
    institution: Research internship, Alchera Inc., Republic of Korea
    onesentence: Changing face and facial expressions of different people using the extracted face landmarks.
    details:
      - key: Description
        value: dfdf
      - key: Role
        value: dfdf
    links:

#   technologies_used: | 
#     Python, Tensorflow, Keras, Matlab


# Others
others: true